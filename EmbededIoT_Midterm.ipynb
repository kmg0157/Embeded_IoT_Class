{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Load the training and test split of the Fashion MNIST dataset\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You can put between 0 to 59999 here\n",
    "index = 1\n",
    "\n",
    "# Set number of characters per row when printing\n",
    "np.set_printoptions(linewidth=320)\n",
    "\n",
    "# Print the label and image\n",
    "print(f'LABEL: {training_labels[index]}')\n",
    "print(f'\\nIMAGE PIXEL ARRAY:\\n {training_images[index]}')\n",
    "\n",
    "# Visualize the image\n",
    "plt.imshow(training_images[index])\n",
    "\n",
    "# Normalize the pixel values of the train and test images\n",
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Build the classification model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# Declare sample inputs and convert to a tensor\n",
    "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print(f'input to softmax function: {inputs.numpy()}')\n",
    "\n",
    "# Feed the inputs to a softmax activation function\n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'output of softmax function: {outputs.numpy()}')\n",
    "\n",
    "# Get the sum of all values after the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "# Get the index with highest value\n",
    "prediction = np.argmax(outputs)\n",
    "print(f'class with highest probability: {prediction}')\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),#optimizer = 'adam'\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluate the model on unseen data\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ccbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') >= 0.88): # Experiment with changing this value\n",
    "            print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac08a7b",
   "metadata": {},
   "source": [
    "# Shallow NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# Setup training parameters\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "print(f'\\nMODEL TRAINING:')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluate on the test set\n",
    "print(f'\\nMODEL EVALUATION:')\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3f35e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b67fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "  # Add convolutions and max pooling\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),    #CNN 사용\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "  # Add the same layers as before\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Use same settings\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "print(f'\\nMODEL TRAINING:')\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluate on the test set\n",
    "print(f'\\nMODEL EVALUATION:')\n",
    "test_loss = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed4fcc9",
   "metadata": {},
   "source": [
    "# W3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f0b8b",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f1c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# Load the data\n",
    "\n",
    "# Get current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append data/mnist.npz to the previous path to get the full path\n",
    "data_path = os.path.join(current_dir, \"data/mnist.npz\")\n",
    "\n",
    "# Get only training set\n",
    "(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c54a1",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f857044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: reshape_and_normalize\n",
    "\n",
    "def reshape_and_normalize(images):\n",
    "\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Reshape the images to add an extra dimension\n",
    "    images = images.reshape((-1, images.shape[1], images.shape[2], 1))\n",
    "    #images=np.expand_dims(images,axis=-1)\n",
    "\n",
    "    # Normalize pixel values\n",
    "    images = images / 255.0\n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return images\n",
    "\n",
    "# Reload the images in case you run this cell multiple times\n",
    "(training_images, _), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
    "\n",
    "# Apply your function\n",
    "training_images = reshape_and_normalize(training_images)\n",
    "\n",
    "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
    "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
    "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n",
    "\n",
    "# GRADED CLASS: myCallback\n",
    "### START CODE HERE\n",
    "\n",
    "# Remember to inherit from the correct class\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') >= 0.995): #accuacy 99.5%이상일 경우 종료\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "### END CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b59ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# GRADED FUNCTION: convolutional_model\n",
    "def convolutional_model():\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "      # Add the same layers as before\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    ### END CODE HERE\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# grader-required-cell\n",
    "\n",
    "# Save your untrained model\n",
    "model = convolutional_model()\n",
    "\n",
    "# Get number of weights\n",
    "model_params = model.count_params()\n",
    "\n",
    "# Unit test to limit the size of the model\n",
    "assert model_params < 1000000, (\n",
    "    f'Your model has {model_params:,} params. For successful grading, please keep it '\n",
    "    f'under 1,000,000 by reducing the number of units in your Conv2D and/or Dense layers.'\n",
    ")\n",
    "\n",
    "# Instantiate the callback class\n",
    "callbacks = myCallback()\n",
    "\n",
    "# Train your model (this can take up to 5 minutes)\n",
    "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5535b84c",
   "metadata": {},
   "source": [
    "# W4\n",
    "### Image Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4cfca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Directory with our training horse pictures\n",
    "train_horse_dir = os.path.join('./horse-or-human/horses')\n",
    "\n",
    "# Directory with our training human pictures\n",
    "train_human_dir = os.path.join('./horse-or-human/humans')\n",
    "\n",
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(train_horse_names[:10])\n",
    "\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(train_human_names[:10])\n",
    "\n",
    "print('total training horse images:', len(os.listdir(train_horse_dir)))\n",
    "print('total training human images:', len(os.listdir(train_human_dir)))\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccada11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './horse-or-human/',  # This is the source directory for training images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=128,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=8,\n",
    "      epochs=15,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c99b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: If you are using Safari and this cell throws an error,\n",
    "## please skip this block and run the next one instead.\n",
    "\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "\n",
    "    # predicting images\n",
    "    path = '/content/' + fn\n",
    "    img = load_img(path, target_size=(300, 300))\n",
    "    x = img_to_array(img)\n",
    "    x /= 255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "\n",
    "    if classes[0]>0.5:\n",
    "    print(fn + \" is a human\")\n",
    "    else:\n",
    "    print(fn + \" is a horse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138e877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#+validation set\n",
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(f'TRAIN SET HORSES: {train_horse_names[:10]}')\n",
    "\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(f'TRAIN SET HUMANS: {train_human_names[:10]}')\n",
    "\n",
    "validation_horse_names = os.listdir(validation_horse_dir)\n",
    "print(f'VAL SET HORSES: {validation_horse_names[:10]}')\n",
    "\n",
    "validation_human_names = os.listdir(validation_human_dir)\n",
    "print(f'VAL SET HUMANS: {validation_human_names[:10]}')\n",
    "\n",
    "print(f'total training horse images: {len(os.listdir(train_horse_dir))}')\n",
    "print(f'total training human images: {len(os.listdir(train_human_dir))}')\n",
    "print(f'total validation horse images: {len(os.listdir(validation_horse_dir))}')\n",
    "print(f'total validation human images: {len(os.listdir(validation_human_dir))}')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_horse_pix = [os.path.join(train_horse_dir, fname)\n",
    "                for fname in train_horse_names[pic_index-8:pic_index]]\n",
    "next_human_pix = [os.path.join(train_human_dir, fname)\n",
    "                for fname in train_human_names[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_horse_pix+next_human_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d55d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './horse-or-human/',  # This is the source directory for training images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=128,\n",
    "        # Since you use binary_crossentropy loss, you need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 128 using validation_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        './validation-horse-or-human/',  # This is the source directory for validation images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=32,\n",
    "        # Since you use binary_crossentropy loss, you need binary labels\n",
    "        class_mode='binary')\n",
    "## NOTE: If you are using Safari and this cell throws an error,\n",
    "## please skip this block and run the next one instead.\n",
    "\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "\n",
    "    # predicting images\n",
    "    path = '/content/' + fn\n",
    "    img = load_img(path, target_size=(300, 300))\n",
    "    x = img_to_array(img)\n",
    "    x /= 255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "        print(fn + \" is a human\")\n",
    "    else:\n",
    "        print(fn + \" is a horse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4a42bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compacted image\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './horse-or-human/',  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=128,\n",
    "        # Since you used binary_crossentropy loss, you need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        './validation-horse-or-human/',  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        # Since you used binary_crossentropy loss, you need binary labels\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Load the first example of a happy face\n",
    "sample_image  = load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\")\n",
    "\n",
    "# Convert the image into its numpy array representation\n",
    "sample_array = img_to_array(sample_image)\n",
    "\n",
    "print(f\"Each image has shape: {sample_array.shape}\")\n",
    "\n",
    "print(f\"The maximum pixel value used is: {np.max(sample_array)}\")\n",
    "\n",
    "# grader-required-cell\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.999:\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "# grader-required-cell\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# GRADED FUNCTION: image_generator\n",
    "def image_generator():\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = train_datagen.flow_from_directory(directory=\"/content/drive/MyDrive/happy_and_sad_files\",\n",
    "                                                        target_size=(150, 150),\n",
    "                                                        batch_size=10,\n",
    "                                                        class_mode='binary')\n",
    "\n",
    "    return train_generator\n",
    "# Save your generator in a variable\n",
    "gen = image_generator()\n",
    "\n",
    "from tensorflow.keras import optimizers, losses\n",
    "import tensorflow as tf\n",
    "\n",
    "# GRADED FUNCTION: train_happy_sad_model\n",
    "def train_happy_sad_model(train_generator):\n",
    "\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    # Select a loss function compatible with the last layer of your network\n",
    "    model.compile(loss=losses.binary_crossentropy,\n",
    "                  optimizer=optimizers.RMSprop(lr=0.001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    # Your model should achieve the desired accuracy in less than 15 epochs.\n",
    "    # You can hardcode up to 20 epochs in the function below but the callback should trigger before 15.\n",
    "    history = model.fit(x=train_generator,\n",
    "                        epochs=20,\n",
    "                        callbacks=[callbacks])\n",
    "    return history\n",
    "\n",
    "hist = train_happy_sad_model(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ee3bc",
   "metadata": {},
   "source": [
    "# C1_W1_Lab_1_hello_world_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04695743",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f817612",
   "metadata": {},
   "source": [
    "### Define & Compile NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4f9b43d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Build a simple Sequential model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Sequential 층을 선형으로 쌓아 구성된 신경망, Dense fully connected layer\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m])])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Build a simple Sequential model\n",
    "# Sequential 층을 선형으로 쌓아 구성된 신경망, Dense fully connected layer\n",
    "# units 층에 있는 뉴런의 수, input_shape 입력 데이터의 형태\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "# Compile the model 모델이 학습될 준비를 하는 것\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe0beb",
   "metadata": {},
   "source": [
    "### Providing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26feba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare model inputs and outputs for training\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cab470",
   "metadata": {},
   "source": [
    "### Training NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7683dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model 실제 학습\n",
    "# xs 입력데이터, ys 출력데이터\n",
    "model.fit(xs, ys, epochs=500)\n",
    "# Make a prediction\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea81bc",
   "metadata": {},
   "source": [
    "# C1_W1_Assingment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c2e2a",
   "metadata": {},
   "source": [
    "### Housing Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d9c2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 11.6317\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 5.4325\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5630\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2345\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6193\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3342\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2019\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1404\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1115\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0978\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0912\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0877\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0858\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0846\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0837\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0830\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0823\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0817\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0811\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0805\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0799\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0793\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0787\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0782\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0776\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0765\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0759\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0754\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0748\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0743\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0737\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0732\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0727\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0721\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0716\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0711\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0706\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0700\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0695\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0690\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0685\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0680\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0675\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0670\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0666\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0661\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0656\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0651\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0646\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0642\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0637\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0632\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0628\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0623\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0619\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0614\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0610\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0605\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0601\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0596\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0592\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0588\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0583\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0579\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0575\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0571\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0567\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0562\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0558\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0554\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0550\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0546\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0542\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0538\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0534\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0531\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0527\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0523\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0519\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0515\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0511\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0508\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0504\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0500\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0497\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0493\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0490\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0486\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0482\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0479\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0475\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0472\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0469\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0465\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0462\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0458\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0455\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0452\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0448\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0445\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0442\n",
      "Epoch 103/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0439\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0435\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0432\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0429\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0426\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0423\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0420\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0417\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0414\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0411\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0408\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0405\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0402\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0399\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0396\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0393\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0390\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0387\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0385\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0382\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0379\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0376\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0373\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0371\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0368\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0365\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0363\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0360\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0357\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0355\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0352\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0350\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0347\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0345\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0342\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0340\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0337\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0335\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0332\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0330\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0327\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0325\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0323\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0320\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0318\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0316\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0313\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0311\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0309\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0307\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0304\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0302\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0300\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0298\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0296\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0293\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0291\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0289\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0287\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0285\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0283\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0281\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0279\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0277\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0275\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0273\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0271\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0267\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0265\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0263\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0261\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0257\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0255\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0253\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0252\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0250\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0248\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0246\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0244\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0243\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0241\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0239\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0237\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0236\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0234\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0232\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0231\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0229\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0227\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0226\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0224\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0221\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0219\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0217\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0216\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0214\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0213\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 204/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0208\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0204\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0198\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0195\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0188\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0186\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0185\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0184\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0182\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0180\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0175\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0172\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0171\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0170\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0158\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0156\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0155\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0151\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0150\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0148\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0146\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0144\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0143\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0142\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0141\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0139\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0138\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0137\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0136\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0135\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0134\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0133\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0132\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0131\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0130\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0129\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0128\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0127\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0127\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0126\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0125\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0124\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0123\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0122\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0121\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0120\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0119\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0118\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0118\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0117\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0116\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0115\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0114\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0113\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0113\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0112\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0111\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0110\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0109\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0109\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0108\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0107\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0106\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0105\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0105\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0104\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0103\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0102\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0102\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0101\n",
      "Epoch 305/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0100\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0099\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0099\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0098\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0097\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0097\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0096\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0094\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0094\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0093\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0092\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0092\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0091\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0090\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0090\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0089\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0088\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0088\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0087\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0087\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0086\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0085\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0085\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0084\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0083\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0083\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0082\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0082\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0081\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0080\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0080\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0079\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0078\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0078\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0077\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0076\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0076\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0075\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0075\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0074\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0074\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0073\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0073\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0072\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0072\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0071\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0071\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0070\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0069\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0069\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0068\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0067\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0067\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0066\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0066\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0066\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0065\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0065\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0064\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0064\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0063\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0063\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0062\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0062\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0061\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0060\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0060\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0059\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0059\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0058\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0058\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0057\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0057\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0056\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0055\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0055\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0054\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0053\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0053\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0053\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0051\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0051\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0051\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0050\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0049\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0049\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0049\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0048\n",
      "Epoch 406/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0048\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0047\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0047\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0046\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0046\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0046\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0045\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0045\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0045\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0044\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0044\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0044\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0044\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0043\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0043\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0043\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0042\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0042\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0042\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0041\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0041\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0041\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0040\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0040\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0039\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0039\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0039\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0038\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0037\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0037\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0037\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0037\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0036\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0036\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0036\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0035\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0034\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0034\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0034\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0033\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0033\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0032\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0032\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0032\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0031\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0031\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0030\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0030\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0029\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0028\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0027\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0027\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0026\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0026\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0026\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0025\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0025\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0024\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0024\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0023\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0023\n",
      "Epoch 507/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0023\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0023\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0023\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0022\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0022\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0022\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0022\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0021\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0020\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0020\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0019\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0019\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0018\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0018\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0018\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0018\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0017\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0017\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0016\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0016\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0016\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0016\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0015\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0015\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0015\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0014\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0014\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0014\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0013\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0013\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0012\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0012\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0011\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0011\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0011\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0010\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0010\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9345e-04\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8622e-04\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7903e-04\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7190e-04\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.6482e-04\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.5779e-04\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.5081e-04\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.4389e-04\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.3701e-04\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.3018e-04\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2340e-04\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.1667e-04\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1000e-04\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0337e-04\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9679e-04\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.9025e-04\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8376e-04\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7733e-04\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7094e-04\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.6459e-04\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.5829e-04\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.5204e-04\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.4583e-04\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3967e-04\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3355e-04\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.2748e-04\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.2145e-04\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1547e-04\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.0953e-04\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0363e-04\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9777e-04\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9196e-04\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.8619e-04\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.8046e-04\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7477e-04\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6913e-04\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6353e-04\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5797e-04\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5244e-04\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4696e-04\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4152e-04\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3611e-04\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3075e-04\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2543e-04\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2014e-04\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1490e-04\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0969e-04\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0452e-04\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9938e-04\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9429e-04\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8923e-04\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8421e-04\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7923e-04\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7428e-04\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6936e-04\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6449e-04\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5964e-04\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5484e-04\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.5007e-04\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4533e-04\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4063e-04\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.3596e-04\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3133e-04\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.2673e-04\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.2217e-04\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.1763e-04\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1313e-04\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0867e-04\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.0423e-04\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.9983e-04\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.9546e-04\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.9112e-04\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.8681e-04\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.8254e-04\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7830e-04\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.7408e-04\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.6990e-04\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6575e-04\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6162e-04\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.5753e-04\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.5347e-04\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.4944e-04\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.4544e-04\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.4146e-04\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3752e-04\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3360e-04\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2972e-04\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2586e-04\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2202e-04\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1822e-04\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1445e-04\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1070e-04\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0698e-04\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0328e-04\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9961e-04\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.9597e-04\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9236e-04\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.8877e-04\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8521e-04\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.8168e-04\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7817e-04\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7469e-04\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7123e-04\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.6779e-04\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.6439e-04\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6100e-04\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.5764e-04\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5431e-04\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.5100e-04\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4771e-04\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4445e-04\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4121e-04\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3800e-04\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3481e-04\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3164e-04\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2850e-04\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2537e-04\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2228e-04\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1920e-04\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1614e-04\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1311e-04\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1010e-04\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0711e-04\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0415e-04\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.0120e-04\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9828e-04\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9538e-04\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9250e-04\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8964e-04\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8680e-04\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8398e-04\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8119e-04\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7841e-04\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7565e-04\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7292e-04\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7020e-04\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6750e-04\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6482e-04\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6217e-04\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5953e-04\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5691e-04\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.5431e-04\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5173e-04\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4916e-04\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4662e-04\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.4409e-04\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4159e-04\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3910e-04\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3663e-04\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3418e-04\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3174e-04\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2932e-04\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2693e-04\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2454e-04\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2218e-04\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1983e-04\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1750e-04\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1519e-04\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1289e-04\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1061e-04\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0835e-04\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0610e-04\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0387e-04\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0166e-04\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9946e-04\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9728e-04\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9511e-04\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9296e-04\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9083e-04\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8871e-04\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8661e-04\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8452e-04\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8245e-04\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8039e-04\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7835e-04\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7632e-04\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7431e-04\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7231e-04\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7032e-04\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6835e-04\n",
      "Epoch 801/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6640e-04\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6446e-04\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6253e-04\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6062e-04\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5872e-04\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5684e-04\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5496e-04\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5311e-04\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5126e-04\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4943e-04\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4761e-04\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4581e-04\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4402e-04\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4224e-04\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4048e-04\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3872e-04\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3699e-04\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3526e-04\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3354e-04\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3184e-04\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3015e-04\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2848e-04\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2681e-04\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2516e-04\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2352e-04\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2189e-04\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2027e-04\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1867e-04\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1708e-04\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1550e-04\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1393e-04\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1237e-04\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1082e-04\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0928e-04\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0776e-04\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0624e-04\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0474e-04\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0325e-04\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0177e-04\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0030e-04\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9884e-04\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9739e-04\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9596e-04\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9453e-04\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9311e-04\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9170e-04\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9031e-04\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8892e-04\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8754e-04\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8618e-04\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8482e-04\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8347e-04\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8214e-04\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8081e-04\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7949e-04\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7818e-04\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7689e-04\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7560e-04\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7432e-04\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7305e-04\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7179e-04\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7054e-04\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6929e-04\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6806e-04\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6684e-04\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6562e-04\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6441e-04\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6322e-04\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6203e-04\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6085e-04\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5967e-04\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5851e-04\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5736e-04\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5621e-04\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5507e-04\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5394e-04\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5282e-04\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5171e-04\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5060e-04\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4950e-04\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4842e-04\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4733e-04\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4626e-04\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4520e-04\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4414e-04\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4309e-04\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4204e-04\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4101e-04\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3998e-04\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3896e-04\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3795e-04\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3695e-04\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3595e-04\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3496e-04\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3397e-04\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3300e-04\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3203e-04\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3107e-04\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3011e-04\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2916e-04\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2822e-04\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2729e-04\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2636e-04\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2544e-04\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2453e-04\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2362e-04\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2272e-04\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2183e-04\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2094e-04\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2006e-04\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1918e-04\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1831e-04\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1745e-04\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1660e-04\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1575e-04\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1490e-04\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1407e-04\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1323e-04\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1241e-04\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1159e-04\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1078e-04\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0997e-04\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0917e-04\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0837e-04\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0758e-04\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0680e-04\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0602e-04\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0525e-04\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0448e-04\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0372e-04\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0297e-04\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0222e-04\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0147e-04\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0073e-04\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9999e-05\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9270e-05\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8547e-05\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7829e-05\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7117e-05\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.6409e-05\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.5707e-05\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5009e-05\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.4318e-05\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.3630e-05\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.2948e-05\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.2271e-05\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.1599e-05\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0931e-05\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0269e-05\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9611e-05\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8958e-05\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8310e-05\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7667e-05\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7028e-05\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6393e-05\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.5765e-05\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.5140e-05\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.4519e-05\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3904e-05\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3292e-05\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.2685e-05\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.2083e-05\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.1485e-05\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.0892e-05\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0302e-05\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9717e-05\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9137e-05\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.8560e-05\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7988e-05\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.7420e-05\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6855e-05\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6296e-05\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5740e-05\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5188e-05\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4640e-05\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.4096e-05\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3557e-05\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3020e-05\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2489e-05\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1961e-05\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1436e-05\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0916e-05\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0399e-05\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9887e-05\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9377e-05\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8872e-05\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8371e-05\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7872e-05\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7378e-05\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6887e-05\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6399e-05\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5916e-05\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5435e-05\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4958e-05\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4485e-05\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4015e-05\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3549e-05\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3086e-05\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.2626e-05\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2170e-05\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "def house_model():\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Define input and output tensors with the values for houses with 1 up to 6 bedrooms\n",
    "    # Hint: Remember to explictly set the dtype as float\n",
    "    xs = np.array([1.0,  2.0, 3.0, 4.0, 5.0, 6.0], dtype=float) #화장실 개수\n",
    "    ys = np.array([1.0, 1.5, 2.0, 2.5, 3.0, 3.5], dtype=float)  #가격\n",
    "\n",
    "    # Define your model (should be a model with 1 dense layer and 1 unit)\n",
    "    model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "\n",
    "    # Compile your model\n",
    "    # Set the optimizer to Stochastic Gradient Descent\n",
    "    # and use Mean Squared Error as the loss function\n",
    "    model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "    # Train your model for 1000 epochs by feeding the i/o tensors\n",
    "    model.fit(xs, ys, epochs=1000)\n",
    "\n",
    "    ### END CODE HERE\n",
    "    return model\n",
    "\n",
    "# Get your trained model\n",
    "model = house_model()\n",
    "\n",
    "#예측하고자 하는 새로운 데이터\n",
    "new_x = 7.0\n",
    "prediction = model.predict([new_x])[0]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c37aeb",
   "metadata": {},
   "source": [
    "# C1_W2_Lab_1_beyond_hello_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e5a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Load the training and test set the Fashion MNIST dataset\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4549ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m np\u001b[38;5;241m.\u001b[39mset_printoptions(linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m320\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Print the label and image\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_labels[index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIMAGE PIXEL ARRAY:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_images[index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Visualize the image\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_labels' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You can put between 0 to 59999 here, 출력할 이미지 인덱스\n",
    "index = 1\n",
    "\n",
    "# Set number of characters per row when printing\n",
    "np.set_printoptions(linewidth=320)\n",
    "\n",
    "# Print the label and image\n",
    "print(f'LABEL: {training_labels[index]}')\n",
    "print(f'\\nIMAGE PIXEL ARRAY:\\n {training_images[index]}')\n",
    "\n",
    "# Visualize the image\n",
    "plt.imshow(training_images[index])\n",
    "\n",
    "# Normalize the pixel values of the train and test images\n",
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Build the classification model\n",
    "model = tf.keras.models.Sequential(\n",
    "    [tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5babec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare sample inputs and convert to a tensor\n",
    "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print(f'input to softmax function: {inputs.numpy()}')\n",
    "\n",
    "# Feed the inputs to a softmax activation function\n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'output of softmax function: {outputs.numpy()}')\n",
    "\n",
    "# Get the sum of all values after the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')\n",
    "\n",
    "# Get the index with highest value\n",
    "prediction = np.argmax(outputs)\n",
    "print(f'class with highest probability: {prediction}')\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluate the model on unseen data\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d65d87",
   "metadata": {},
   "source": [
    "### Ex1"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "27aac782",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bfe701",
   "metadata": {},
   "source": [
    "### Ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential(\n",
    "    [tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d503e2ee",
   "metadata": {},
   "source": [
    "### Ex8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ab3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') >= 0.88): # Experiment with changing this value\n",
    "            print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef6571",
   "metadata": {},
   "source": [
    "# C1_W2_Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b304a1",
   "metadata": {},
   "source": [
    "### Callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43460311",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') >= 0.99): # Experiment with changing this value\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc1901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist(x_train, y_train):\n",
    "\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Instantiate the callback class\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model for 10 epochs adding the callbacks\n",
    "    # and save the training history\n",
    "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62745795",
   "metadata": {},
   "source": [
    "# C1_W3_Lab_1_improving_accuracy_using convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff5c1e",
   "metadata": {},
   "source": [
    "### Shallow NN(앝은 신경망:은닉층의 수가 적거나 뉴런수가 적은 것)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00842f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "  # Add convolutions and max pooling\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),    #CNN 사용\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "  # Add the same layers as before\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Use same settings\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "print(f'\\nMODEL TRAINING:')\n",
    "model.fit(training_images, training_labels, epochs=5) #epoch 5\n",
    "\n",
    "# Evaluate on the test set\n",
    "print(f'\\nMODEL EVALUATION:')\n",
    "test_loss = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ca581",
   "metadata": {},
   "source": [
    "1. 컨볼루션의 필터 수를 변경하면 모델의 파라미터 수와 학습 시간이 변할 수 있습니다. 예를 들어, 필터 수를 줄이면 학습할 파라미터 수가 감소하므로 학습 시간이 줄어들 수 있습니다. 그러나 모델의 표현력은 줄어들 수 있으므로 정확도에 영향을 줄 수 있습니다.\n",
    "\n",
    "2. 마지막 컨볼루션을 제거하면 모델의 특징 추출 능력이 감소할 수 있습니다. 따라서 모델의 정확도가 감소할 수 있습니다. 학습 시간에는 큰 변화가 없을 수 있습니다.\n",
    "\n",
    "3. 추가적인 컨볼루션을 추가하면 모델이 더 많은 이미지 특징을 학습할 수 있습니다. 그러나 추가된 컨볼루션은 더 많은 파라미터를 가지므로 모델의 복잡도가 증가하고 학습 시간이 증가할 수 있습니다. 이는 정확도를 향상시킬 수 있지만 과적합의 가능성도 증가시킬 수 있습니다.\n",
    "\n",
    "4. 모든 컨볼루션을 제거하면 모델이 이미지의 공간적 구조를 고려하지 않고 전역적인 특징만을 학습할 수 있습니다. 따라서 모델의 표현 능력이 제한되어 정확도가 감소할 수 있습니다.\n",
    "\n",
    "5. 이전 레슨에서 구현한 콜백을 사용하여 특정 손실 값에 도달하면 훈련을 중지할 수 있습니다. 콜백은 특정 조건이 충족될 때 호출되고, 여기서는 손실 값이 일정 수준 이하로 떨어질 때 훈련을 중지시키도록 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a4a5f8",
   "metadata": {},
   "source": [
    "### 컨볼루션의 필터 수 변경하기: 컨볼루션 레이어의 필터 수를 16 또는 64로 변경하여 정확도와 학습 시간에 어떤 영향을 미치는지 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f177cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 Conv2D 레이어의 필터 수를 16으로 변경\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448c582a",
   "metadata": {},
   "source": [
    "#### 컨볼루션 레이어에서 필터 수를 변경하는 것은 모델의 복잡성과 표현 능력을 조절하는 중요한 요소입니다. 필터 수를 줄이면 모델의 파라미터 수가 감소하고, 더 많은 픽셀 수를 고려하여 더 많은 특징을 추출할 수 있습니다. 그러나 필터 수를 늘리면 모델이 더 많은 특징을 학습할 수 있지만, 학습 시간이 늘어날 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f180343",
   "metadata": {},
   "source": [
    "### 마지막 컨볼루션 제거하기: 마지막 컨볼루션 레이어를 제거하여 정확도와 학습 시간에 어떤 영향을 미치는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b821ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # 마지막 컨볼루션 레이어 제거\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dda981",
   "metadata": {},
   "source": [
    "#### 마지막 컨볼루션 레이어를 제거하면 모델이 더 간단해질 것으로 예상됩니다. 이 레이어가 이미지의 공간적인 특징을 더 깊이 추출하는 데 도움을 주기는 하지만, 제거함으로써 모델이 학습할 파라미터 수가 감소하고 모델의 복잡성이 줄어들 것으로 예상됩니다. 따라서 학습 시간이 줄어들 수 있지만, 모델의 표현력이 줄어들어 정확도에 영향을 줄 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfdc1fe",
   "metadata": {},
   "source": [
    "### 더 많은 컨볼루션 추가하기: 추가적인 컨볼루션 레이어를 추가하여 정확도와 학습 시간에 어떤 영향을 미치는지 실험합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3677f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가적인 Conv2D 레이어를 추가\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),  # 추가된 Conv2D 레이어\n",
    "    tf.keras.layers.MaxPooling2D(2,2),  # 추가된 MaxPooling2D 레이어\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036efd",
   "metadata": {},
   "source": [
    "#### 추가된 컨볼루션 레이어는 입력 이미지의 다양한 특징을 추출하고, 이를 통해 모델이 데이터를 더 잘 이해하고 분류할 수 있습니다. 그러나 더 많은 컨볼루션 레이어를 추가할 경우 모델의 파라미터 수와 학습 시간이 증가할 수 있으며, 과적합의 위험이 높아질 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47074a5f",
   "metadata": {},
   "source": [
    "### 모든 컨볼루션 제거하기: 모든 컨볼루션 레이어를 제거하여 정확도와 학습 시간에 어떤 영향을 미치는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),  # 첫 번째 컨볼루션 레이어만 사용\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bc4ae0",
   "metadata": {},
   "source": [
    "##### 모델의 표현 능력이 제한될 것으로 예상됩니다. 모델은 이미지의 전역적인 패턴을 파악하고 분류하는 데 어려움을 겪을 수 있으며, 이로 인해 정확도가 감소할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be62360f",
   "metadata": {},
   "source": [
    "### 콜백 구현하기: 손실 함수를 모니터링하여 특정 임계값 이하가 될 때 훈련을 중지시키는 콜백을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01527b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실이 특정 값 이하로 떨어지면 훈련을 중지하는 콜백 클래스 정의\n",
    "class LossCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('loss') < 0.1:  # 특정 임계값 이하로 손실이 떨어지면\n",
    "            print(\"\\nReached loss less than 0.1, so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# 콜백을 사용하여 모델 훈련\n",
    "model.fit(training_images, training_labels, epochs=10, callbacks=[LossCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72227226",
   "metadata": {},
   "source": [
    "# C1_W3_Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417c790f",
   "metadata": {},
   "source": [
    "### Improve MNIST with Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# grader-required-cell\n",
    "\n",
    "# Load the data\n",
    "\n",
    "# Get current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append data/mnist.npz to the previous path to get the full path\n",
    "data_path = os.path.join(current_dir, \"mnist.npz\")\n",
    "\n",
    "# Get only training set(붙여서 사용할것)\n",
    "(training_images, training_labels), _ \n",
    "= tf.keras.datasets.mnist.load_data(path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f7beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: reshape_and_normalize\n",
    "\n",
    "def reshape_and_normalize(images):\n",
    "\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Reshape the images to add an extra dimension\n",
    "    images = np.expand_dims(images, axis=-1)\n",
    "    #axis 매개 변수에는 몇 가지 옵션이 있습니다:\n",
    "    #None 또는 -1: 배열의 마지막 축에 새로운 축을 추가합니다.\n",
    "    #0: 배열의 첫 번째 축에 새로운 축을 추가합니다.\n",
    "    #1: 배열의 두 번째 축에 새로운 축을 추가합니다.\n",
    "    #그 외의 다른 양수 또는 음수 값: 해당 인덱스에 새로운 축을 추가합니다.\n",
    "\n",
    "    # Normalize pixel values\n",
    "    images = images / 255.0\n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb812a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# Reload the images in case you run this cell multiple times\n",
    "(training_images, _), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
    "\n",
    "# Apply your function\n",
    "training_images = reshape_and_normalize(training_images)\n",
    "\n",
    "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
    "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
    "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f0f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CLASS: myCallback\n",
    "### START CODE HERE\n",
    "\n",
    "# Remember to inherit from the correct class\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') >= 0.995): #accuacy 99.5%이상일 경우 종료\n",
    "            print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8c931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convolutional_model\n",
    "def convolutional_model():\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "      # Add the same layers as before\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    ### END CODE HERE\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50669c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# Save your untrained model\n",
    "model = convolutional_model()\n",
    "\n",
    "# Get number of weights\n",
    "model_params = model.count_params()\n",
    "\n",
    "# Unit test to limit the size of the model\n",
    "assert model_params < 1000000, (\n",
    "    f'Your model has {model_params:,} params. For successful grading, please keep it '\n",
    "    f'under 1,000,000 by reducing the number of units in your Conv2D and/or Dense layers.'\n",
    ")\n",
    "\n",
    "# Instantiate the callback class\n",
    "callbacks = myCallback()\n",
    "\n",
    "# Train your model (this can take up to 5 minutes)\n",
    "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])\n",
    "\n",
    "print(f\"Your model was trained for {len(history.epoch)} epochs\")\n",
    "\n",
    "if not \"accuracy\" in history.model.metrics_names:\n",
    "    print(\"Use 'accuracy' as metric when compiling your model.\")\n",
    "else:\n",
    "    print(\"The metric was correctly defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f1b601",
   "metadata": {},
   "source": [
    "# C1_W4_Lab_1_image_generator_no_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292daaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# Unzip the dataset\n",
    "local_zip = './horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./horse-or-human')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ea228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory with our training horse pictures\n",
    "train_horse_dir = os.path.join('./horse-or-human/horses')\n",
    "\n",
    "# Directory with our training human pictures\n",
    "train_human_dir = os.path.join('./horse-or-human/humans')\n",
    "\n",
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(train_horse_names[:10])\n",
    "\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(train_human_names[:10])\n",
    "\n",
    "print('total training horse images:', len(os.listdir(train_horse_dir)))\n",
    "print('total training human images:', len(os.listdir(train_human_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_horse_pix = [os.path.join(train_horse_dir, fname)\n",
    "                for fname in train_horse_names[pic_index-8:pic_index]]\n",
    "next_human_pix = [os.path.join(train_human_dir, fname)\n",
    "                for fname in train_human_names[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_horse_pix+next_human_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17cdd2d",
   "metadata": {},
   "source": [
    "#### make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3809e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 \n",
    "    # with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. \n",
    "    # It will contain a value from 0-1 \n",
    "    # where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79699549",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31922aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './horse-or-human/',  # This is the source directory for training images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=128,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=8,\n",
    "      epochs=15,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdcc490",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d97140",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: If you are using Safari and this cell throws an error,\n",
    "## please skip this block and run the next one instead.\n",
    "\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "\n",
    "  # predicting images\n",
    "    path = '/content/' + fn\n",
    "    img = load_img(path, target_size=(300, 300))\n",
    "    x = img_to_array(img)\n",
    "    x /= 255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "\n",
    "    if classes[0]>0.5:\n",
    "    print(fn + \" is a human\")\n",
    "    else:\n",
    "    print(fn + \" is a horse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a9dc9",
   "metadata": {},
   "source": [
    "# C1_W4_Lab_2_with_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0528b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory with training horse pictures\n",
    "train_horse_dir = os.path.join('./horse-or-human/horses')\n",
    "\n",
    "# Directory with training human pictures\n",
    "train_human_dir = os.path.join('./horse-or-human/humans')\n",
    "\n",
    "# Directory with validation horse pictures\n",
    "validation_horse_dir = os.path.join('./validation-horse-or-human/horses')\n",
    "\n",
    "# Directory with validation human pictures\n",
    "validation_human_dir = os.path.join('./validation-horse-or-human/humans')\n",
    "\n",
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(f'TRAIN SET HORSES: {train_horse_names[:10]}')\n",
    "\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(f'TRAIN SET HUMANS: {train_human_names[:10]}')\n",
    "\n",
    "validation_horse_names = os.listdir(validation_horse_dir)\n",
    "print(f'VAL SET HORSES: {validation_horse_names[:10]}')\n",
    "\n",
    "validation_human_names = os.listdir(validation_human_dir)\n",
    "print(f'VAL SET HUMANS: {validation_human_names[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b4a13e",
   "metadata": {},
   "source": [
    "#### 나머지는 Lab1과 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ca1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './horse-or-human/',  # This is the source directory for training images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=128,\n",
    "        # Since you use binary_crossentropy loss, you need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 128 using validation_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        './validation-horse-or-human/',  # This is the source directory for validation images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=32,\n",
    "        # Since you use binary_crossentropy loss, you need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=8,\n",
    "      epochs=15,\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a86db4c",
   "metadata": {},
   "source": [
    "# C1_W4_Lab_3_compacted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da41701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './horse-or-human/',  # This is the source directory for training images\n",
    "        #이미지 사이즈 조정    \n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=128,\n",
    "        # Since you used binary_crossentropy loss, you need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        './validation-horse-or-human/',  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        # Since you used binary_crossentropy loss, you need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=8,\n",
    "      epochs=15,\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde07c3",
   "metadata": {},
   "source": [
    "#### 작은 이미지를 사용하면 학습 및 검증 시간이 감소할 수 있지만, 모델이 이미지의 일부 정보를 잃을 수 있습니다. 따라서 target_size를 변경하면 학습 및 검증 시의 모델 성능에 영향을 미칠 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9065bc",
   "metadata": {},
   "source": [
    "# C1_W4_Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb1b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "happy_dir = \"/content/drive/MyDrive/happy_and_sad_files/happy_files\"\n",
    "sad_dir = \"/content/drive/MyDrive/happy_and_sad_files/sad_files\"\n",
    "\n",
    "print(\"Sample happy image:\")\n",
    "plt.imshow(load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSample sad image:\")\n",
    "plt.imshow(load_img(f\"{os.path.join(sad_dir, os.listdir(sad_dir)[0])}\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b3ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Load the first example of a happy face\n",
    "sample_image  = load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\")\n",
    "\n",
    "# Convert the image into its numpy array representation\n",
    "sample_array = img_to_array(sample_image)\n",
    "\n",
    "print(f\"Each image has shape: {sample_array.shape}\")\n",
    "\n",
    "print(f\"The maximum pixel value used is: {np.max(sample_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc702d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.999:\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa893a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# GRADED FUNCTION: image_generator\n",
    "def image_generator():\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = train_datagen.flow_from_directory(directory=\"happy_and_sad_files\",\n",
    "                                                        target_size=(150, 150),\n",
    "                                                        batch_size=10,\n",
    "                                                        class_mode='binary')\n",
    "\n",
    "    return train_generator\n",
    "\n",
    "# Save your generator in a variable\n",
    "gen = image_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7239027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers, losses\n",
    "import tensorflow as tf\n",
    "\n",
    "# GRADED FUNCTION: train_happy_sad_model\n",
    "def train_happy_sad_model(train_generator):\n",
    "\n",
    "    # Instantiate the callback\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    # Select a loss function compatible with the last layer of your network\n",
    "    model.compile(loss=losses.binary_crossentropy,\n",
    "                  optimizer=optimizers.RMSprop(lr=0.001),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    # Your model should achieve the desired accuracy in less than 15 epochs.\n",
    "    # You can hardcode up to 20 epochs in the function below but the callback should trigger before 15.\n",
    "    history = model.fit(x=train_generator,\n",
    "                        epochs=20,\n",
    "                        callbacks=[callbacks])\n",
    "    ### END CODE HERE\n",
    "    return history\n",
    "\n",
    "hist = train_happy_sad_model(gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
